{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "python_to_web.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTVBk1gPRBFs"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WBNHf67C3y3"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW68LYzn4XL6"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/MendezJesus/python_to_web/blob/main/python_to_web.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/MendezJesus/python_to_web/blob/main/python_to_web.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez2xSm9LVh-h"
      },
      "source": [
        "# Run a neural network in the browser\n",
        "\n",
        "This notebook contains an example of training a neural network using TensorFlow and Python, then running it in the browser using TensorFlow.js. If you run this notebook in Colab using *Runtime -> Run all*, it will create a webpage that you can use interactively to classify images you upload through a user interface.\n",
        "\n",
        "This notebook provides example code to do the following:\n",
        "\n",
        "1. Train a neural network using Python to classify flowers\n",
        "1. Save the model to disk\n",
        "1. Convert the model to TensorFlow.js format\n",
        "1. Create a webpage using a minimum amount of HTML and JavaScript to run the model\n",
        "1. Serve the webpage from this notebook (instructions are also provided to serve the page locally)\n",
        "1. Upload images through the UI and classify them with the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y30fDjA4opRI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ9pE0UB9iIu"
      },
      "source": [
        "## Install Tensorflow.js and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSW64X_G7Ela"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og5MWUyoG2Pj"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks38bmgRA-xO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import json\n",
        "import matplotlib\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.models import Model\n",
        "from google.colab import html\n",
        "from IPython.display import HTML\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbEsQrjFosm0"
      },
      "source": [
        "# Train a model using Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T-yp3DrG_l8"
      },
      "source": [
        "## Load the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAdXhn36YnuE"
      },
      "source": [
        "The first half of this tutorial trains a convolutional neural network to classify images of flowers, based on this [tutorial](https://www.tensorflow.org/tutorials/images/classification). The steps that are repeated here are only lightly commented, and you can refer to the original tutorial to learn more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRYep9qMqG15"
      },
      "source": [
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
        "                                   fname='flower_photos', \n",
        "                                   untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGKKZZ8PIb7w"
      },
      "source": [
        "There are 3670 total flower images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGCU5oYUc4Nu"
      },
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk6lMXWfIpE2"
      },
      "source": [
        "Define parameters for the loader.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P51UwMqe7EO"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW44eWS6IuZO"
      },
      "source": [
        "It's good practice to use a validation split when developing your model. We will use 80% of the images for training, and 20% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxIT-TEpevKt"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61NrMw90ev2u"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkBbFvdtI7SI"
      },
      "source": [
        "The flower dataset contains 5 different type of flowers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GuvXKOdf1eC"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RN5vhM1I5e6"
      },
      "source": [
        "## Visualize the data\n",
        "\n",
        "Here are the first 9 images from the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYkK6IMlfK65"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOU-sTh8lDgD"
      },
      "source": [
        "Displays an image of a sunflower that can be classified later in the webpage.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9SDL0-fkrlb"
      },
      "source": [
        "plt.imshow(images[3].numpy().astype(\"uint8\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USOFTY9aSpZM"
      },
      "source": [
        "## Standardize the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYWeLqNCZt-H"
      },
      "source": [
        "Note: It is important that you preprocess images identically in Python and JavaScript. This notebook uses a Python preprocessing layer which is not yet available in TensorFlow.js. As a workaround, you will normalize the images in JavaScript manually, as shown later in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y58B56bnSo7h"
      },
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvU9qOB8LVtz"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq9eXfoxglWv"
      },
      "source": [
        "num_classes = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfOYLTVTgprL"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftO1gfFhgtaf"
      },
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=5\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6uUs8pchRuu"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa4Xueu9aF4K"
      },
      "source": [
        "# Save and convert the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLv6lW0cF371"
      },
      "source": [
        "Save the TensorFlow model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuuLJJszDAy1"
      },
      "source": [
        "model.save(\"tfjs/myModel.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6gmDKxZF4vQ"
      },
      "source": [
        "Convert an existing TensorFlow model to the TensorFlow.js web format. \n",
        "\n",
        "The conversion will produce two types of files:\n",
        "\n",
        "\n",
        "1. model.json (the dataflow graph and weight manifest)\n",
        "1. group1-shard\\*of\\* (collection of binary weight files)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEQDf17W9uyo"
      },
      "source": [
        "!tensorflowjs_converter \\\n",
        "    --input_format=keras \\\n",
        "    tfjs/myModel.h5 \\\n",
        "    tfjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aNCRWJQKFFq"
      },
      "source": [
        "# Develop the Website\n",
        "\n",
        "This notebook contains a small amount of HTML and JavaScript, stored as Python strings inside code cells below. This is close to the minimum amount of code necessary to run the model in the browser (along with some CSS for the UI). Running the code cells below will save this HTML and JavaScript to disk, then serve the page from inside this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Xh61JxKL2u"
      },
      "source": [
        "## JavaScript\n",
        "\n",
        "This code include helper functions to prepare the data, classify images, and display the model's prediction in HTML elements that will be defined in the next block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEezv_Lf9w6S"
      },
      "source": [
        "js_template = \"\"\"\n",
        "const CLASSES = [\n",
        "  'Daisy',\n",
        "  'Dandelion',\n",
        "  'Rose',\n",
        "  'Sunflower',\n",
        "  'Tulips',\n",
        "];\n",
        "\n",
        "const MODEL_PATH = '<model_url>';\n",
        "const IMAGE_SIZE = 180;\n",
        "const TOPK_PREDICTIONS = 5;\n",
        "\n",
        "let myModel = undefined;\n",
        "const DEMO = async () => {\n",
        "  status('Loading model...');\n",
        "\n",
        "  myModel = await tf.loadLayersModel(MODEL_PATH);\n",
        "\n",
        "  // Warmup the model. This isn't necessary, but makes the first prediction\n",
        "  // faster. Call `dispose` to release the WebGL memory allocated for the return\n",
        "  // value of `predict`.\n",
        "  myModel.predict(tf.zeros([1, IMAGE_SIZE, IMAGE_SIZE, 3])).dispose();\n",
        "\n",
        "  status('');\n",
        "\n",
        "  // Make a prediction through the locally hosted cat.jpg.\n",
        "  const inputImage = document.getElementById('inputimg');\n",
        "  if (inputImage.complete && inputImage.naturalHeight !== 0) {\n",
        "    predict(inputImage);\n",
        "    inputImage.style.display = '';\n",
        "  } else {\n",
        "    inputImage.onload = () => {\n",
        "      predict(inputImage);\n",
        "      inputImage.style.display = '';\n",
        "    }\n",
        "  }\n",
        "};\n",
        "\n",
        "/**\n",
        " * Uses an image to make a prediction using myModel.\n",
        " * @param imgElement is converted to a tensor and then normalized to make\n",
        " * prediction.\n",
        " */\n",
        "async function predict(imgElement) {\n",
        "  status('Predicting...');\n",
        "\n",
        "  // The first start time includes the time it takes to extract the image\n",
        "  // from the HTML and preprocess it, in additon to the predict() call.\n",
        "  const startTime1 = performance.now();\n",
        "  // The second start time excludes the extraction and preprocessing and\n",
        "  // includes only the predict() call.\n",
        "  let startTime2 = 0;\n",
        "  const logits = tf.tidy(() => {\n",
        "    // tf.browser.fromPixels() returns a Tensor from an image element.\n",
        "    const img = tf.browser.fromPixels(imgElement).toFloat();\n",
        "\n",
        "    // Normalize the image from [0, 255] to [-1, 1].\n",
        "    const normalized = img.div(255.0);\n",
        "\n",
        "    // Reshape to a single-element batch so we can pass it to predict.\n",
        "    const batched = normalized.reshape([1, IMAGE_SIZE, IMAGE_SIZE, 3]);\n",
        "\n",
        "    startTime2 = performance.now();\n",
        "    // Make a prediction through myModel.\n",
        "    return myModel.predict(batched);\n",
        "  });\n",
        "\n",
        "  // Convert logits to probabilities and class names.\n",
        "  const {values, indices} = tf.topk(logits, TOPK_PREDICTIONS);\n",
        "  const indicesArray = indices.arraySync();\n",
        "  const valuesArray = values.arraySync();\n",
        "\n",
        "  const classes = [];\n",
        "  for (let i = 0; i < CLASSES.length; i++) {\n",
        "    classes.push({\n",
        "      className: CLASSES[indicesArray[0][i]],\n",
        "      probability: valuesArray[0][i]\n",
        "    })\n",
        "  }\n",
        "\n",
        "  const totalTime1 = performance.now() - startTime1;\n",
        "  const totalTime2 = performance.now() - startTime2;\n",
        "  status(`Done in ${Math.floor(totalTime1)} ms ` +\n",
        "      `(not including preprocessing: ${Math.floor(totalTime2)} ms)`);\n",
        "\n",
        "  // Show the classes in the DOM.\n",
        "  showResults(imgElement, classes);\n",
        "}\n",
        "\n",
        "/**\n",
        " * UI\n",
        " * Maps flower class with corresponding probability.\n",
        " * @param classes contains flower class name and corresponding prediction.\n",
        " */\n",
        "function showResults(imgElement, classes) {\n",
        "\n",
        "  const predictionContainer = document.createElement('div');\n",
        "  const imgContainer = document.createElement('div');\n",
        "  imgContainer.appendChild(imgElement);\n",
        "  predictionContainer.appendChild(imgContainer);\n",
        "\n",
        "  const table = document.createElement(\"table\");\n",
        "  const tableBody = document.createElement(\"tbody\");\n",
        "\n",
        "  for (let i = 0; i < classes.length; i++) {\n",
        "    var row = document.createElement(\"tr\");\n",
        "    var cell = document.createElement(\"td\");\n",
        "    var cell2 = document.createElement(\"td\");\n",
        "    var cellTextFlowerName = document.createTextNode(classes[i].className);\n",
        "    var cellTextProbability = document.createTextNode(classes[i].probability.toFixed(3));\n",
        "    cell.appendChild(cellTextFlowerName);\n",
        "    cell2.appendChild(cellTextProbability);\n",
        "    row.appendChild(cell);\n",
        "    row.appendChild(cell2);\n",
        "    tableBody.appendChild(row);\n",
        "  }\n",
        "  table.appendChild(tableBody);\n",
        "\n",
        "  predictionContainer.appendChild(table);\n",
        "\n",
        "  predictionsElement.insertBefore(\n",
        "      predictionContainer, predictionsElement.firstChild);\n",
        "}\n",
        "\n",
        "const filesElement = document.getElementById('files');\n",
        "filesElement.addEventListener('change', evt => {\n",
        "  let files = evt.target.files;\n",
        "  // Display thumbnails & issue call to predict each image.\n",
        "  for (let i = 0, f; f = files[i]; i++) {\n",
        "    // Only process image files (skip non image files)\n",
        "    if (!f.type.match('image.*')) {\n",
        "      continue;\n",
        "    }\n",
        "    let reader = new FileReader();\n",
        "    const idx = i;\n",
        "    // Closure to capture the file information.\n",
        "    reader.onload = e => {\n",
        "      // Fill the image & call predict.\n",
        "      let img = document.createElement('img');\n",
        "      img.src = e.target.result;\n",
        "      img.width = IMAGE_SIZE;\n",
        "      img.height = IMAGE_SIZE;\n",
        "      img.onload = () => predict(img);\n",
        "    };\n",
        "\n",
        "    // Read in the image file as a data URL.\n",
        "    reader.readAsDataURL(f);\n",
        "  }\n",
        "});\n",
        "\n",
        "const DEMO_STATUS_ELEMENT = document.getElementById('status');\n",
        "const status = msg => DEMO_STATUS_ELEMENT.innerText = msg;\n",
        "\n",
        "const predictionsElement = document.getElementById('predictions');\n",
        "\n",
        "DEMO();\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QVpZZe6FkVf"
      },
      "source": [
        "## HTML\n",
        "The HTML below contains element IDs that will be populated by the JavaScript."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJyzitag8Mrg"
      },
      "source": [
        "html_template = \"\"\"\n",
        "<!doctype html>\n",
        "\n",
        "<head>\n",
        "  <title>Your title</title>\n",
        "  <meta charset=\"UTF-8\">\n",
        "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
        "</head>\n",
        "\n",
        "<body>\n",
        "  <div class=\"tfjs-example-container\">\n",
        "      <h1>TensorFlow.js: Using a Keras model in the browser</h1>\n",
        "      <p>Description</p>\n",
        "      <p>\n",
        "        This file is based on <a>https://github.com/tensorflow/tfjs-examples/tree/master/mobilenet</a>.\n",
        "      </p>\n",
        "      <p>Status</p>\n",
        "      <div id=\"status\"></div>\n",
        "      <p>Model Output</p>\n",
        "       <label for=\"file\">Upload an image:</label>\n",
        "       <input type=\"file\" id=\"files\" name=\"files[]\" multiple />\n",
        "      <p id=\"predictions\"></p>\n",
        "      <img style=\"display: none\" id=\"inputimg\" src=\"{sunflower_url}\" crossorigin=\"anonymous\" width=180 height=180 />\n",
        "    <script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js\"></script>\n",
        "    <script>{js_content}</script>\n",
        "  </div>\n",
        "</body>\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1H4vwM7v7ip8"
      },
      "source": [
        "# Serve the model from this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMx0T0bXszwG"
      },
      "source": [
        "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/models/tfjs/python_to_web/sunflower.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riahnbOYklBc"
      },
      "source": [
        "# Create a resource and make it available for http request.\n",
        "\n",
        "def CreateModelResources(some_path, file=\"\"):\n",
        "  # Create resource for model.json\n",
        "  model_path = some_path + file\n",
        "  ref = html.create_resource(filepath = model_path, route = model_path)\n",
        "\n",
        "  weight_path_list = []\n",
        "  with open(model_path, 'r') as f:\n",
        "    model_json = json.load(f)\n",
        "    weightsManifest = model_json['weightsManifest']\n",
        "    for weightGroup in weightsManifest:\n",
        "      weight_path_list.extend(weightGroup['paths'])\n",
        "\n",
        "  # Create resource for each weight path.\n",
        "  refs = []\n",
        "  for path in weight_path_list:\n",
        "    weight_path = some_path + '/' + path\n",
        "    with open(weight_path, 'rb') as f:\n",
        "      weights = f.read()\n",
        "      weight_path = html.create_resource(content=weights, route=weight_path)\n",
        "      refs.append(weight_path)\n",
        "\n",
        "  return ref, refs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rus-4kImkuJj"
      },
      "source": [
        "(ref, refs) = CreateModelResources(\"/content/tfjs\", \"/model.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z29CCbX-kuhT"
      },
      "source": [
        "js_content_final = js_template.replace(\"<model_url>\", ref.url)\n",
        "html_content_final = html_template.format(sunflower_url=sunflower_url, js_content=js_content_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B2_A8BOkuwV"
      },
      "source": [
        "HTML(html_content_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxKlWb8svmjK"
      },
      "source": [
        "# Prepare the HTML to run locally\n",
        "# by replacing the model path with a local directory\n",
        "import re\n",
        "html_content_final = re.sub(\"const MODEL_PATH =.+\", \n",
        "                            \"const MODEL_PATH = 'model.json';\", \n",
        "                            html_content_final)\n",
        "with open('/content/tfjs/index.html', 'w') as f:\n",
        "    f.write(html_content_final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie7x-gRSBFeZ"
      },
      "source": [
        "# Run locally\n",
        "\n",
        "This example has the files embedded within the Colab for convenience, but you can run serve the model locally on your computer by starting your own webserver. To do so:\n",
        "\n",
        "1. Run this notebook (either in Colab, on on your computer) to create the saved model and index.html. \n",
        "\n",
        "1. Download the converted model (including the weights and json) and index.html file from ```/content/tfjs/``` in Colab to your local machine. If you don't see that directory in the file browser, click the refresh icon.\n",
        "\n",
        "1. Start a web server on your local machine (if you simply open index.html in a browser, you may run into security protections that prevent it from loading scripts. To start a server, you can use one built-in to Python. First, `cd` into your `tfds` directory.  Using Python3, run this command in your terminal:\n",
        "\n",
        " `$ python3 -m http.server 8888`\n",
        "\n",
        "1. Now, open a browser to the generated port(e.g. point the URL to `localhost:8888`). Your webpage should appear. To debug, in Chrome you can open the Javascript console via ```View - Developer -> Developer tools -> Console```. Check if there are any errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-kiiErAGizg"
      },
      "source": [
        "# Next Steps\n",
        "Explore another example of how to convert a SavedModel to TensorFlow.js in this [codelab](https://codelabs.developers.google.com/codelabs/tensorflowjs-convert-python-savedmodel), and\n",
        "to learn more about image classification please checkout this [tutorial](https://www.tensorflow.org/tutorials/images/classification). You can learn more about converting models [here](https://www.tensorflow.org/js/tutorials/conversion/import_keras), and you find an additional example of image classification in the browser [here](https://github.com/tensorflow/tfjs-examples/tree/master/mobilenet).\n"
      ]
    }
  ]
}
